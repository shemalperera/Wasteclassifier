{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split completed. Training: C:/Users/HPA02532Y/Documents\\GitHub/Wasteclassifier/Data\\train, Validation: C:/Users/HPA02532Y/Documents\\GitHub/Wasteclassifier/Data\\val, Testing: C:/Users/HPA02532Y/Documents\\GitHub/Wasteclassifier/Data\\test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "def split_dataset(dataset_path, output_path, train_ratio=0.6, val_ratio=0.2, test_ratio=0.2):\n",
    "   \n",
    "    assert train_ratio + val_ratio + test_ratio == 1.0, \"Ratios must sum to 1\"\n",
    "\n",
    "    train_dir = os.path.join(output_path, \"train\")\n",
    "    val_dir = os.path.join(output_path, \"val\")\n",
    "    test_dir = os.path.join(output_path, \"test\")\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    for class_name in os.listdir(dataset_path):\n",
    "        class_path = os.path.join(dataset_path, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        # Gather all file paths in the current class\n",
    "        files = os.listdir(class_path)\n",
    "        random.shuffle(files)  \n",
    "\n",
    "        total_files = len(files)\n",
    "        train_end = int(total_files * train_ratio)\n",
    "        val_end = train_end + int(total_files * val_ratio)\n",
    "\n",
    "        # Split files\n",
    "        train_files = files[:train_end]\n",
    "        val_files = files[train_end:val_end]\n",
    "        test_files = files[val_end:]\n",
    "\n",
    "        # Copy files to respective directories\n",
    "        for file in train_files:\n",
    "            src = os.path.join(class_path, file)\n",
    "            dest = os.path.join(train_dir, class_name)\n",
    "            os.makedirs(dest, exist_ok=True)\n",
    "            shutil.copy(src, dest)\n",
    "\n",
    "        for file in val_files:\n",
    "            src = os.path.join(class_path, file)\n",
    "            dest = os.path.join(val_dir, class_name)\n",
    "            os.makedirs(dest, exist_ok=True)\n",
    "            shutil.copy(src, dest)\n",
    "\n",
    "        for file in test_files:\n",
    "            src = os.path.join(class_path, file)\n",
    "            dest = os.path.join(test_dir, class_name)\n",
    "            os.makedirs(dest, exist_ok=True)\n",
    "            shutil.copy(src, dest)\n",
    "\n",
    "    print(f\"Dataset split completed. Training: {train_dir}, Validation: {val_dir}, Testing: {test_dir}\")\n",
    "\n",
    "dataset_path = \"C:/Users/HPA02532Y/Documents\\GitHub/Wasteclassifier/RealWaste\"  \n",
    "output_path = \"C:/Users/HPA02532Y/Documents\\GitHub/Wasteclassifier/Data\" \n",
    "split_dataset(dataset_path, output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
